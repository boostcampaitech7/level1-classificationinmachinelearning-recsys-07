{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01cbcf7f-88b4-4eb1-b691-3cfb424650c7",
   "metadata": {},
   "source": [
    "### 일반적임 똑같음 \n",
    "절차과정 : nan값 가지고있는 피쳐링에 각각 mean 을 넣어보기도함 (test낮음)\n",
    "그래서 결국  nan값 -999 baaseline 과같이 동일하게함\n",
    "baseline 이랑 동일(피쳐링개수빼고)\n",
    "내 생각: 그냥 baseline 에있는 피쳐들 따라가면서 board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4f537-ee2f-4dd7-8c96-34e888dc24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87510eb8-371a-4a3b-9ffa-592d05b25f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2024-04-26 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>2024-04-26 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>2024-04-26 05:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>2024-04-26 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>2024-04-26 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11552 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  target  _type\n",
       "0     2023-01-01 00:00:00     2.0  train\n",
       "1     2023-01-01 01:00:00     1.0  train\n",
       "2     2023-01-01 02:00:00     1.0  train\n",
       "3     2023-01-01 03:00:00     1.0  train\n",
       "4     2023-01-01 04:00:00     2.0  train\n",
       "...                   ...     ...    ...\n",
       "2787  2024-04-26 03:00:00     NaN   test\n",
       "2788  2024-04-26 04:00:00     NaN   test\n",
       "2789  2024-04-26 05:00:00     NaN   test\n",
       "2790  2024-04-26 06:00:00     NaN   test\n",
       "2791  2024-04-26 07:00:00     NaN   test\n",
       "\n",
       "[11552 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 호출\n",
    "data_path: str = \"data\"\n",
    "train_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"train.csv\")).assign(_type=\"train\") # train 에는 _type = train \n",
    "test_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")).assign(_type=\"test\") # test 에는 _type = test\n",
    "submission_df: pd.DataFrame = pd.read_csv(os.path.join(data_path, \"test.csv\")) # ID, target 열만 가진 데이터 미리 호출\n",
    "df: pd.DataFrame = pd.concat([train_df, test_df], axis=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6b52d9-1830-41ef-84e8-4982f739387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 107/107 [00:01<00:00, 77.75it/s]\n"
     ]
    }
   ],
   "source": [
    "file_names : List[str]=[\n",
    "    f for f in os.listdir(data_path) if f.startswith('HOURLY_') and f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "file_dict: Dict[str,pd.DataFrame]={\n",
    "    f.replace(\".csv\",\"\"): pd.read_csv(os.path.join(data_path,f)) for f in file_names\n",
    "}\n",
    "\n",
    "for _file_name, _df in tqdm(file_dict.items()):\n",
    "    _rename_rule={\n",
    "        col: f\"{_file_name.lower()}_{col.lower()}\" if col!=\"datetime\" else \"ID\"\n",
    "        for col in _df.columns\n",
    "    }\n",
    "    _df=_df.rename(_rename_rule,axis=1)\n",
    "    df=df.merge(_df,on=\"ID\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad0577a-6b21-41b8-821a-b1ab237f24d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11552, 215)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "missing_values=df.isnull().sum()\n",
    "missing_values\n",
    "missing_percentage= (missing_values)/len(df) *100\n",
    "missing_percentage\n",
    "\n",
    "sorted_missing_percentage=missing_percentage.sort_values(ascending=False)\n",
    "\n",
    "# null 100 percent인 feature들\n",
    "name_null=[]\n",
    "for col, val in sorted_missing_percentage.items():\n",
    "    if val==100:\n",
    "        name_null.append(col)        \n",
    "len(name_null)\n",
    "for i in name_null:\n",
    "    df=df.drop(columns=i)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d6336-ea11-43ee-8aa8-f5f04e6a448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#내일 베이스라인의 선택적인 컬럼만 가져와서 nan값에 넣고 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8323f56-239f-46d7-81a1-34346d9b61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dict : Dict[str,str] = {}\n",
    "for i in df.columns:\n",
    "    \n",
    "    parts=i.split(\"_\")\n",
    "    if len(parts)>=3:\n",
    "        cols_dict[i]=\"_\".join(parts[2:])\n",
    "    else:\n",
    "        cols_dict[i]=i\n",
    "\n",
    "cols_dict2: Dict[str, str] = {\n",
    "    \"ID\": \"ID\",\n",
    "    \"target\": \"target\",\n",
    "    \"_type\": \"_type\",\n",
    "    \"coinbase-premium-index_coinbase_premium_gap\": \"coinbase_premium_gap\",\n",
    "    \"coinbase-premium-index_coinbase_premium_index\": \"coinbase_premium_index\",\n",
    "    \"funding-rates_all_exchange_funding_rates\": \"funding_rates\",\n",
    "    \"liquidations_all_exchange_all_symbol_long_liquidations\": \"long_liquidations\",\n",
    "    \"liquidations_all_exchange_all_symbol_long_liquidations_usd\": \"long_liquidations_usd\",\n",
    "    \"liquidations_all_exchange_all_symbol_short_liquidations\": \"short_liquidations\",\n",
    "    \"liquidations_all_exchange_all_symbol_short_liquidations_usd\": \"short_liquidations_usd\",\n",
    "    \"open-interest_all_exchange_all_symbol_open_interest\": \"open_interest\",\n",
    "    \"taker-buy-sell-stats_all_exchange_taker_buy_ratio\": \"buy_ratio\",\n",
    "    \"taker-buy-sell-stats_all_exchange_taker_buy_sell_ratio\": \"buy_sell_ratio\",\n",
    "    \"taker-buy-sell-stats_all_exchange_taker_buy_volume\": \"buy_volume\",\n",
    "    \"taker-buy-sell-stats_all_exchange_taker_sell_ratio\": \"sell_ratio\",\n",
    "    \"taker-buy-sell-stats_all_exchange_taker_sell_volume\": \"sell_volume\",\n",
    "    \"addresses-count_addresses_count_active\": \"active_count\",\n",
    "    \"addresses-count_addresses_count_receiver\": \"receiver_count\",\n",
    "    \"addresses-count_addresses_count_sender\": \"sender_count\",\n",
    "}\n",
    "cols_dict\n",
    "df = df[cols_dict.keys()].rename(cols_dict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519f14ca-3189-462e-a2ae-655384546730",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_dict2.keys():\n",
    "    df = df.rename(columns={i: cols_dict2[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6abe25-dd91-48b8-a8b2-7f8b77bb2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a7d6f-c223-43f8-9692-00cb06c60194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nan 값 채우기\n",
    "# eda_df=df.loc[df[\"_type\"]==\"train\"]\n",
    "# eda_test=df.loc[df[\"_type\"]==\"test\"]\n",
    "# missing_values = eda_df.isnull().sum()\n",
    "# missing_percentage = (missing_values / len(eda_df)) * 100\n",
    "# sorted_missing_percentage = missing_percentage.sort_values(ascending=False)\n",
    "\n",
    "# # Identify columns with missing values\n",
    "# null = [col for col in eda_df.columns if missing_values[col] != 0]\n",
    "\n",
    "# # Fill missing values with the mean of each column\n",
    "# for col in null:\n",
    "#     eda_df.loc[:, col] = eda_df[col].fillna(eda_df[col].mean())\n",
    "    \n",
    "# missing_values2 = eda_test.isnull().sum()\n",
    "# missing_percentage2 = (missing_values2 / len(eda_test)) * 100\n",
    "# sorted_missing_percentage2 = missing_percentage2.sort_values(ascending=False)\n",
    "\n",
    "# null_test=[col for col in eda_test.columns if missing_values2[col] !=0 and col!='target']\n",
    "\n",
    "# for col in null_test:\n",
    "#     eda_test.loc[:,col] = eda_test[col].fillna(eda_df[col].mean())\n",
    "\n",
    "# df=pd.concat([eda_df,eda_test],axis=0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec140e9-c77b-4bd7-ab31-5cb248e9600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    liquidation_diff=df[\"long_liquidations\"]-df[\"short_liquidations\"],\n",
    "    liquidation_usd_diff= df['long_liquidations_usd']-df['short_liquidations_usd'],\n",
    "    volume_diff=df[\"buy_volume\"] - df[\"sell_volume\"],\n",
    "    liquidation_diffg=np.sign(df[\"long_liquidations\"]-df[\"short_liquidations\"]),\n",
    "    liquidation_usd_diffg=np.sign(df['long_liquidations_usd']-df['short_liquidations_usd']),\n",
    "    volume_diffg=np.sign(df[\"buy_volume\"] - df[\"sell_volume\"]),\n",
    "    buy_sell_volume_ratio=df[\"buy_volume\"] / (df[\"sell_volume\"] + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45ccc4-591d-43e0-8e5f-bdbc3fcad39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_cols : List[str] = [\"liquidation_diffg\", \"liquidation_usd_diffg\", \"volume_diffg\"]\n",
    "# conti_cols: List[str] = [ i for i in df.columns \n",
    "#                          if i not in [\"ID\",\"target\",\"_type\",\"liquidation_diffg\", \"liquidation_usd_diffg\", \"volume_diffg\"]]\n",
    "# len(conti_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735b0c5-b5f6-475b-9897-2a13d4dd5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shift_feature(\n",
    "#     df: pd.DataFrame,\n",
    "#     conti_cols: List[str],\n",
    "#     intervals: List[int],\n",
    "# ) -> List[pd.Series]:\n",
    "#     \"\"\"\n",
    "#     연속형 변수의 shift feature 생성\n",
    "#     Args:\n",
    "#         df (pd.DataFrame)\n",
    "#         conti_cols (List[str]): continuous colnames\n",
    "#         intervals (List[int]): shifted intervals\n",
    "#     Return:\n",
    "#         List[pd.Series]\n",
    "#     \"\"\"\n",
    "#     df_shift_dict = [\n",
    "#         df[conti_col].shift(interval).rename(f\"{conti_col}_{interval}\")\n",
    "#         for conti_col in conti_cols\n",
    "#         for interval in intervals\n",
    "#     ]\n",
    "#     return df_shift_dict\n",
    "\n",
    "# # 최대 24시간의 shift 피쳐를 계산\n",
    "# shift_list = shift_feature(\n",
    "#     df=df, conti_cols=conti_cols, intervals=[_ for _ in range(1, 24)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca43ce3d-df4d-4463-83b6-14841833b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df, pd.concat(shift_list, axis=1)], axis=1)\n",
    "\n",
    "# # 타겟 변수를 제외한 변수를 forwardfill, -999로 결측치 대체\n",
    "_target = df[\"target\"]\n",
    "df = df.ffill().fillna(-999).assign(target = _target)\n",
    "\n",
    "# _type에 따라 train, test 분리\n",
    "train_df = df.loc[df[\"_type\"]==\"train\"].drop(columns=[\"_type\"])\n",
    "test_df = df.loc[df[\"_type\"]==\"test\"].drop(columns=[\"_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9e1c4c2-b189-4103-ab48-05c36fa080f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinseunghun/anaconda3/envs/my_proejct/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4360730593607306, auroc: 0.6388032318060743\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train_df.drop([\"target\", \"ID\"], axis = 1), \n",
    "    train_df[\"target\"].astype(int), \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# lgb dataset\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "valid_data = lgb.Dataset(x_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "# lgb params\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_class\": 4,\n",
    "    \"num_leaves\": 50,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 30,\n",
    "    \"random_state\": 42,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "# lgb train\n",
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=valid_data,\n",
    ")\n",
    "\n",
    "# lgb predict\n",
    "y_valid_pred = lgb_model.predict(x_valid)\n",
    "y_valid_pred_class = np.argmax(y_valid_pred, axis = 1)\n",
    "\n",
    "# score check\n",
    "accuracy = accuracy_score(y_valid, y_valid_pred_class)\n",
    "auroc = roc_auc_score(y_valid, y_valid_pred, multi_class=\"ovr\")\n",
    "\n",
    "print(f\"acc: {accuracy}, auroc: {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a021aa4-bb58-4e1e-8683-0635cd500968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Feature  Importance\n",
      "36       open-interest_bitfinex_btc_usdt_open_interest         149\n",
      "139        price-ohlcv_all_exchange_spot_btc_usd_close         114\n",
      "57         taker-buy-sell-stats_bybit_taker_buy_volume         113\n",
      "33   open-interest_htx_global_all_symbol_open_interest         112\n",
      "42      taker-buy-sell-stats_deribit_taker_sell_volume          99\n",
      "81    taker-buy-sell-stats_htx_global_taker_buy_volume          95\n",
      "175      taker-buy-sell-stats_bitmex_taker_sell_volume          93\n",
      "193                funding-rates_deribit_funding_rates          89\n",
      "143                      block-interval_block_interval          88\n",
      "73         tokens-transferred_tokens_transferred_total          85\n",
      "74          tokens-transferred_tokens_transferred_mean          83\n",
      "165  open-interest_huobi_global_btc_usdt_open_interest          82\n",
      "155           taker-buy-sell-stats_okx_taker_buy_ratio          81\n",
      "54                                      receiver_count          79\n",
      "171                    funding-rates_okx_funding_rates          79\n",
      "140       price-ohlcv_all_exchange_spot_btc_usd_volume          76\n",
      "173         transactions-count_transactions_count_mean          73\n",
      "17                             block-bytes_block_bytes          72\n",
      "30    open-interest_huobi_global_btc_usd_open_interest          71\n",
      "117                               coinbase_premium_gap          69\n",
      "43        taker-buy-sell-stats_deribit_taker_buy_ratio          69\n",
      "58        taker-buy-sell-stats_bybit_taker_sell_volume          69\n",
      "53                                        sender_count          66\n",
      "72      open-interest_binance_all_symbol_open_interest          65\n",
      "41       taker-buy-sell-stats_deribit_taker_buy_volume          64\n",
      "55           open-interest_bybit_btc_usd_open_interest          63\n",
      "172        transactions-count_transactions_count_total          63\n",
      "82   taker-buy-sell-stats_htx_global_taker_sell_volume          62\n",
      "76       open-interest_kraken_all_symbol_open_interest          60\n",
      "25         open-interest_deribit_btc_usd_open_interest          60\n"
     ]
    }
   ],
   "source": [
    "importance = lgb_model.feature_importance()\n",
    "feature_names=train_df.drop([\"target\", \"ID\"], axis = 1).columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "})\n",
    "\n",
    "# Sort by importance (optional)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(feature_importance_df[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75d32679-cae4-4927-81b7-b54dc6fb3d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinseunghun/anaconda3/envs/my_proejct/lib/python3.9/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "# performance 체크후 전체 학습 데이터로 다시 재학습\n",
    "x_train = train_df.drop([\"target\", \"ID\"], axis = 1)\n",
    "y_train = train_df[\"target\"].astype(int)\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=train_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ddf453-5650-481b-8cb5-4a6db7a6c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb predict\n",
    "y_test_pred = lgb_model.predict(test_df.drop([\"target\", \"ID\"], axis = 1))\n",
    "y_test_pred_class = np.argmax(y_test_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b398d971-2809-433c-957a-4a5e3ca77116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file 할당후 save \n",
    "submission_df = submission_df.assign(target = y_test_pred_class)\n",
    "submission_df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
